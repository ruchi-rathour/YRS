# -*- coding: utf-8 -*-
"""Untitled30.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12mhFmi2fKIoQf3YZRAHg5DQUgSvm5AHr
"""

!wget http://nlp.stanford.edu/data/glove.6B.zip

!unzip glove*.zip

!ls
!pwd

import numpy as np

print('Indexing word vectors.')

embeddings_index = {}
f = open('glove.6B.300d.txt', encoding='utf-8')
for line in f:
    values = line.split()
    word = values[0]
    coefs = np.asarray(values[1:], dtype='float32')
    embeddings_index[word] = coefs
f.close()

print('Found %s word vectors.' % len(embeddings_index))

try:
  embeddings_index['pranic']
except:
  print('not_found')

import numpy as np

def cosine_similarity_calc(vec_1,vec_2):
	
	sim = np.dot(vec_1,vec_2)/(np.linalg.norm(vec_1)*np.linalg.norm(vec_2))
	
	return sim

A = np.array([0.1,0.7])
B = np.array([0.2, 0.6])
C = np.array([0.8,0.1])

print('Sentence A and B smilarity:',cosine_similarity_calc(A,B))
print('Sentence A and C smilarity:',cosine_similarity_calc(A,C))

cosine_similarity_calc(embeddings_index['pain'],embeddings_index['arthritis'])

from google.colab import drive
drive.mount('/content/drive')

data = '/content/drive/MyDrive/yrs/final_asan1.csv'
# data = 'final_asan1.csv'

import re
from textblob import TextBlob
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from gensim.parsing.preprocessing import remove_stopwords

benefits = []
contra = []
asan_lst = []

import csv

with open(data,'r') as file:
  reader = csv.reader(file)
  for row in reader:
    benefits.append(row[5])
    contra.append(row[6])
    asan_lst.append(row[1])

input_1=[]
input_2=[]
output=[]
data = []

for i in range (len(benefits)):
  line = benefits[i]
  line = line.lower()
  line = re.sub(r'[^A-Za-z\n]+', ' ', line)
  line = remove_stopwords(line)
  line = line.replace("benefits","")
  input_1.append(line)
  data.append(line)
  line = contra[i]
  line = line.lower()
  line = re.sub(r'[^A-Za-z\n]+', ' ', line)
  line = remove_stopwords(line)
  line = line.replace("contra","")
  line = line.replace("indications","")
  input_2.append(line)
  data.append(line)
  line = asan_lst[i]
  line = line.replace(" ","")
  output.append(line)

benefits[4]

class asans:
  def __init__(self,asan,sim1,sim2):
    self.asan = asan
    self.sim1 = sim1
    self.sim2 = sim2

  def __repr__(self):
    return f'{self.asan} has a sim1 score of {self.sim1} and a sim2 score of {self.sim2}'

def cmp_sim1(obj):
  return obj.sim1

user = "head"   ## try obesity, pregnancy
lst = list()
text =[]
for i in range(len(input_1)):
    text = input_1[i].split(" ")
    sim1=0
    sim2=0
    for j in text:
      if j not in ['']:
        try:
          sim1 = max(sim1,cosine_similarity_calc(embeddings_index[j],embeddings_index[user]))
        except:
          sim1 = sim1
    text2 = input_2[i].split(" ")
    for j in text2:
      if j not in ['']:
        try:
          sim2 = max(sim2,cosine_similarity_calc(embeddings_index[j],embeddings_index[user]))
        except:
          sim2 = sim2
    obj = asans(output[i],sim1,sim2)
    if sim1>0.6 and sim2 < 0.3:
      lst.append(obj)

lst.sort(key = cmp_sim1)

for obj in lst:
  print(obj)

len(lst)

for i in range(len(output)):
  if output[i] == 'TADASANA':
    print(asan_lst[i])
    print(benefits[i])
    print(contra[i])

